{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe4dacc-9fe5-4d75-abec-1e86f4bdccdd",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f1065-eb19-48ba-b813-d53e51f80b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f0d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (\n",
    "    Tool,\n",
    "    AgentExecutor,\n",
    "    LLMSingleActionAgent,\n",
    "    AgentOutputParser,\n",
    ")\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39113714-d599-4579-ac9a-d4bd11b767e6",
   "metadata": {},
   "source": [
    "### Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5d46ee-7eb0-4f5c-a87a-7a1cf77b377c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keys import apikey, aws_access_key_id, aws_secret_access_key\n",
    "import os\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "#os.environ['aws_access_key_id'] = aws_access_key_id\n",
    "#os.environ['aws_secret_access_key'] = aws_secret_access_key\n",
    "aws_access_key_id=\"\"\n",
    "aws_secret_access_key=\"\"\n",
    "\n",
    "class LambdaRMQ(BaseTool):\n",
    "    name = 'Lambda function for RMQ firewall rules'\n",
    "    description = \"\"\"Do NOT use this tool until you have received all input arguments from the user directly.\n",
    "    \n",
    "                    Use this tool to invoke a lambda function to create security group rules for only \"RMQ\" or \"RabbitMQ\".\n",
    "                    \n",
    "                    If the port is not for \"RabbitMQ\" or \"RMQ\", do not create a rule. Respond that you cannot open that port.\n",
    "                    \n",
    "                    Do not attempt to create a security group rule that is not for \"RabbitMQ\" or \"RMQ\" with this tool.\n",
    "                    \n",
    "                    ONLY accept action_input or input of \"RMQ\" or \"RabbitMQ\".\n",
    "        \n",
    "                    DO NOT accept action_input or input of anything else.\n",
    "                    \"\"\"\n",
    "\n",
    "    def _run(self, get_log=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Do NOT use this tool until you have asked for the 'cidr' input argument.\n",
    "        \n",
    "        Use this tool to invoke a lambda function to create security group rules for only \"RMQ\" or \"RabbitMQ\"\n",
    "        \n",
    "        If the security group rule is not for \"RabbitMQ\" or \"RMQ\", do not create a rule. Respond that you cannot create that rule. \n",
    "\n",
    "        Only invoke the lambda function for input of \"RMQ\" or \"RabbitMQ\".\n",
    "        \n",
    "        ONLY accept action_input or input of \"RMQ\" or \"RabbitMQ\".\n",
    "        \n",
    "        DO NOT accept action_input or input of anything else. \n",
    "\n",
    "        :return: The response from the function invocation.\n",
    "        \"\"\"\n",
    "        print(\"In the function\")\n",
    "        client = boto3.client('lambda', region_name='us-east-1', aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key)\n",
    "\n",
    "        cidr_ranges = {'vdi': '10.10.64.0/24', 'surface': '10.10.65.0/24', 'development': '192.168.0.0/24'}\n",
    "        cidr = ''\n",
    "        if cidr == '':\n",
    "            try:\n",
    "                cidr = cidr_ranges.get(input(str('Please provide the group that will need access. (for example; vdi, surface, or development)')).lower())\n",
    "            except KeyError:\n",
    "                print('That is not a valid entry')\n",
    "                _run()\n",
    "        else:\n",
    "            return 'Something went wrong. Please try again.'\n",
    "   \n",
    "        \n",
    "        inputParams = {\n",
    "        'cidr'    : cidr\n",
    "        }\n",
    "        \n",
    "        response = client.invoke(\n",
    "            FunctionName='darcy-agent-test-sg-rmq',\n",
    "            Payload = json.dumps(inputParams)\n",
    "            )\n",
    "        return \"I have created your security group rules for RMQ!\"\n",
    "\n",
    "    def _arun(self, sops):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "\n",
    "class LambdaHTTPS(BaseTool):\n",
    "    name = 'Lambda function for HTPPS firewall rules'\n",
    "    description = \"\"\"Use this tool to invoke a lambda function to create security group rules for only HTTPS.\n",
    "                    \n",
    "                    If the port is not for HTTPS, do not create a rule. Respond that you cannot open that port.\n",
    "                    \n",
    "                    Do not attempt to create a security group rule that is not for HTTPS with this tool.\n",
    "                    \n",
    "                    ONLY accept action_input or input of HTTPS.\n",
    "        \n",
    "                    DO NOT accept action_input or input of anything else.\n",
    "                    \n",
    "                    \"\"\"\n",
    "\n",
    "    def _run(self, function_name, get_log=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Use this tool to invoke a lambda function to create security group rules for only HTTPS\n",
    "        \n",
    "        If the port is not for HTTPS, do not create a rule. Respond that you cannot open that port.\n",
    "\n",
    "        Only invoke the lambda function for input of HTTPS.\n",
    "        \n",
    "        ONLY accept action_input or input of HTTPS.\n",
    "        \n",
    "        DO NOT accept action_input or input of anything else.\n",
    "        \n",
    "        :return: The response from the function invocation.\n",
    "        \"\"\"\n",
    "        \n",
    "        client = boto3.client('lambda', region_name='us-east-1', aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key)\n",
    "\n",
    "        response = client.invoke(\n",
    "            FunctionName='darcy-agent-test-sg-https'\n",
    "            )\n",
    "        return \"I have created your security group rules for HTTPS!\"\n",
    "\n",
    "    def _arun(self, sops):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c75a22-d982-435b-8968-a4bfde530c36",
   "metadata": {},
   "source": [
    "### Create LLM, Memory, Agent, and Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608e176a-ac94-4f12-b148-317fb484b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=apikey,\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=2,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f15f4a53-8483-4d06-846a-71fd51b40a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "tools = [LambdaRMQ(), LambdaHTTPS()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    #agent='zero-shot-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a525640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=t.description, metadata={\"index\": i})\n",
    "    for i, t in enumerate(tools)\n",
    "]\n",
    "vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def get_tools(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return [tools[d.metadata[\"index\"]] for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a508f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tools(\"Make me some coffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are a world-class python coder. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You will be expected to modify the Python code from the most relevant tool provided to accomodate\n",
    "what the Question is asking for.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! \n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05638b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dffc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6488ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "tools = get_tools(\"what tools change security groups\")\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a46dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"What tool can perform RDP security group changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dbbbd-b8ba-44ca-b7ee-e974edf8030a",
   "metadata": {},
   "source": [
    "### Interact with the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16202ed5-8165-4aa9-a822-07bbb6567ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Lambda function for RMQ firewall rules\",\n",
      "    \"action_input\": \"RMQ\"\n",
      "}\u001b[0mIn the function\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mI have created your security group rules for RMQ!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The security group rules for RabbitMQ have been created successfully.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you create security group rules for RabbitMQ?',\n",
       " 'chat_history': [],\n",
       " 'output': 'The security group rules for RabbitMQ have been created successfully.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent('Can you create security group rules for RabbitMQ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55776347-6c52-4779-84c8-a64bbf85eabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#agent('Can you create a firewall rule for RDP?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
