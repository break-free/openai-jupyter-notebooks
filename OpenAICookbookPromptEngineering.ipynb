{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e0ea3-bd06-4a03-b4a1-88a3f0bb84b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setup installation of packages and what to import/consume later:\n",
    "%pip install scipy\n",
    "%pip install tokenizers\n",
    "%pip install openai\n",
    "\n",
    "import regex\n",
    "import IPython.display\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import openai\n",
    "import re\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import CharBPETokenizer as CBPET\n",
    "from tokenizers import ByteLevelBPETokenizer as BBPET\n",
    "from tokenizers import SentencePieceBPETokenizer as SPBPET\n",
    "from tokenizers import BertWordPieceTokenizer as BWPT\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1cd74-bb1d-4cc6-b9c2-06bf76a8d768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set the opeanAI API key:\n",
    "openai.api_key_path = 'openai-key.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7021dc5-ecd1-426c-973c-03165085c5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Unit Test Scraper Functions\n",
    "Below Unit Test Finder functions find SOME unit tests in *.java files. Makes the following assumptions:\n",
    "    - Unit Test starts with \"@Test <return character><tab character> public void\"\n",
    "    - Unit Test does NOT throw any exception, and thus just has a return character after its declaration\n",
    "\n",
    "Also cleans up\n",
    "    - single-line comments\n",
    "    - multi-line comments\n",
    "    - empty new lines\n",
    "\n",
    "With the above assumptions it finds 465 of the 588 unit test cases littered throughout the fineract application\n",
    "\"\"\"\n",
    "\n",
    "# Regex Pattern to Scrap Unit Tests:\n",
    "pattern = r\"@Test\\s*public\\s*void\\s*\\w+\\s*\\(\\s*\\)\\s*\\{[^{}]*+(?:(?:\\{[^{}]*+\\})*+[^{}]*+)*+\\}\"\n",
    "\n",
    "def remove_comments(java_code):\n",
    "    # Remove single-line comments\n",
    "    java_code = re.sub(r\"//.*\", \"\", java_code)\n",
    "\n",
    "    # Remove multi-line comments\n",
    "    java_code = re.sub(r\"/\\*(.|[\\r\\n])*?\\*/\", \"\", java_code)\n",
    "\n",
    "    # Remove empty white lines:\n",
    "    java_code = re.sub(r\"\\n\\s*\\n\", \"\\n\", java_code)\n",
    "\n",
    "    # Remove Unit Tests:\n",
    "    java_code = delete_java_unit_tests(java_code)\n",
    "    \n",
    "    return java_code\n",
    "\n",
    "def DirectoryUnitTestSearch(directory, delete=False):\n",
    "    test_blocks = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".java\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r+\") as f:\n",
    "                    java_code = f.read()\n",
    "                    test_blocks.extend(find_java_unit_tests(java_code))\n",
    "                    if delete == True:\n",
    "                        modified_code = delete_java_unit_tests(java_code)\n",
    "                        f.seek(0)\n",
    "                        f.write(modified_code)\n",
    "                        f.truncate()\n",
    "                        f.seek(0)\n",
    "                        f.write(modified_code)\n",
    "    \n",
    "    return test_blocks\n",
    "\n",
    "def find_java_unit_tests(text):\n",
    "    test_blocks = []\n",
    "    matches = re.finditer(pattern, text, re.MULTILINE)\n",
    "    matches_lst = [i.group(0) for i in matches]\n",
    "    for item in matches_lst:\n",
    "        if item: # Only add non-empty matches\n",
    "            test_blocks.append(item)\n",
    "            # print(f\"List of matches: {item}\")\n",
    "\n",
    "    return test_blocks\n",
    "\n",
    "def delete_java_unit_tests(text):\n",
    "    modified_code = re.sub(pattern, \"\", text, flags=re.MULTILINE)\n",
    "    return modified_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fbd9a-5bff-41bf-bd48-b2df0b922d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Set up the codebase chunks and embed them\n",
    "    - Clone the repo down (commented out right now so I don't have to wait for a clone each time it fails)\n",
    "    - Extract & Clean (using above remove_comments() function) the java files\n",
    "    - Chunk the java files into 1600 token chunks\n",
    "    - Store the chunks in memory\n",
    "    - Send the chunks off to openAI's embedding API endpoint (using text-embedding-ada-002)\n",
    "    - Store the embedded text as a Pandas Dataframe\n",
    "    - Print the dataframe (just to be sure)\n",
    "\"\"\"\n",
    "\n",
    "repo_dir = \"fineract\"  # Use the cleaned repo\n",
    "# Clone the GitHub repository -- should really only need to do this once\n",
    "# repo_url = \"https://github.com/apache/fineract\"\n",
    "# subprocess.run([\"git\", \"clone\", \"-b\", \"1.8.4\", repo_url, repo_dir]) # Grab the 1.8.4 fineract git branch just because it's stable\n",
    "\n",
    "# Set up the tokenizer\n",
    "# tokenizer = BBPET()  # Byte\n",
    "tokenizer = SPBPET()   # Sentence\n",
    "\n",
    "\n",
    "java_files = []\n",
    "for root, dirs, files in os.walk(repo_dir):\n",
    "    if dirs == \"test\":\n",
    "        os.rmdir(dirs)\n",
    "    for file in files:\n",
    "        if file.endswith(\".java\"):\n",
    "            java_files.append(os.path.join(root, file))\n",
    "\n",
    "# Process the Java files and break them into 1600 token chunks\n",
    "new_dir = \"fineract-java\"\n",
    "output_dir = \"java_files_chunks_sentence\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for file in java_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        java_code = f.read()\n",
    "\n",
    "    # Use the remove_comments function to redefine java_code as sans-comments java code:\n",
    "    java_code = remove_comments(java_code)\n",
    "\n",
    "    new_filename = f\"cleaned-{os.path.basename(file)}\"\n",
    "    new_filepath = os.path.join(new_dir, new_filename)\n",
    "\n",
    "    with open(new_filepath, \"w\") as f:\n",
    "        f.write(java_code)\n",
    "\n",
    "new_java_files = []\n",
    "for root, dirs, files in os.walk(new_dir):\n",
    "    if dirs == \"test\":\n",
    "        os.rmdir(dirs)\n",
    "    for file in files:\n",
    "        if file.endswith(\".java\"):\n",
    "            new_java_files.append(os.path.join(root, file))\n",
    "\n",
    "# Train the tokenizer on the Java files:\n",
    "# tokenizer_trainer = BpeTrainer(vocab_size=1600, min_frequency=2)\n",
    "tokenizer.train(new_java_files)\n",
    "\n",
    "output_content = []\n",
    "for file in new_java_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        new_java_code = f.read()\n",
    "\n",
    "    encoding = tokenizer.encode(new_java_code)\n",
    "    tokens = encoding.tokens\n",
    "    ids = encoding.ids\n",
    "    chunk_size = 1600\n",
    "    num_chunks = (len(tokens) + chunk_size - 1) // chunk_size\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = (i + 1) * chunk_size\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunk_ids = ids[start:end]\n",
    "        chunk_code = tokenizer.decode(chunk_ids)\n",
    "\n",
    "        chunk_filename = os.path.basename(file) + f\".chunk{i+1}.java\"\n",
    "        chunk_filepath = os.path.join(output_dir, chunk_filename)\n",
    "\n",
    "        output_content.append(chunk_code)\n",
    "        # If you want to visualize the tokenized java chunks, uncomment the following two lines:\n",
    "        # with open(chunk_filepath, \"w\") as f:\n",
    "        #     f.write(chunk_code)\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Number of token chunks to send at a time\n",
    "# OpenAI's example specifies 1000 but I've had greater success with 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(output_content), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = output_content[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({\"text\": output_content, \"embedding\": embeddings})\n",
    "\n",
    "# Print out the Dataframe, just to be sure:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd891e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[Optional] Cell to test the regex pattern for finding unit tests\"\"\"\n",
    "print(f\"Output_dir: {output_dir}\")\n",
    "print(f\"new_dir: {new_dir}\")\n",
    "\n",
    "test_blocks1 = DirectoryUnitTestSearch(output_dir, True)\n",
    "test_blocks2 = DirectoryUnitTestSearch(new_dir, True)\n",
    "\n",
    "if os.listdir(output_dir) != []:\n",
    "    print(f\"Number of Test Blocks found in {output_dir}: {len(test_blocks1)}, or {len(test_blocks1)/588*100:.2f}% (assuming 588 test cases)\")\n",
    "if os.listdir(new_dir) != []:\n",
    "    print(f\"Number of Test Blocks found in {new_dir}: {len(test_blocks2)}, or {len(test_blocks2)/588*100:.2f}% (assuming 588 test cases)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13785bd-f7e3-4c2c-a8ce-52aae71e9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data directory so that py is happy\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# save document chunks and embeddings\n",
    "SAVE_PATH = \"data/fineract.csv\"\n",
    "\n",
    "df.to_csv(SAVE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de4d4b-a0e7-464f-93ff-330e9decfb86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Setup the dataframe and CSV datastore\"\"\"\n",
    "embeddings_path = SAVE_PATH\n",
    "\n",
    "df = pd.read_csv(embeddings_path)\n",
    "\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357093c1-9cfe-4f2b-8190-e68e3b541803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Setup the vector search function that scrapes through your dataframe and/or CSV file to find related code based on your prompt\n",
    "\"\"\"\n",
    "\n",
    "# search function\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f5c52-ed3d-44c0-ad13-9f8c9c032740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"[Optional] Test the vector scraping from the embedded text\n",
    "    Don't actually need to run this, but it's good to understand\n",
    "    what it's doing under the hood\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Write a new unit test for 'Delete a code' for the CodesApiResource class\"\n",
    "\n",
    "strings, relatednesses = strings_ranked_by_relatedness(prompt, df, top_n=3)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf27de-37c2-4c08-82e9-2b31011c1f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the functions for how to reach out to ChatGPT\n",
    "    use by calling ask(<prompt>)\n",
    "    Can optionally get the hidden context printed by typing\n",
    "\n",
    "        ask(<prompt>, print_message=True)\n",
    "\"\"\"\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below codeset from the fineract java web application to answer the subsequent question. If the answer cannot be found from the code sample, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nFineract Application codebase selection:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about the Fineract Web Application.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c019aee-6d0d-4964-830b-7198e0965fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Call out to ChatGPT\n",
    "\n",
    "Syntax:\n",
    "    \n",
    "    ask(\"<prompt>\", print_message=<True/False>)\n",
    "\n",
    "print_message defaults to false; if set to True it displays the hidden context along with the answer provided by ChatGPT\n",
    "\"\"\"\n",
    "\n",
    "# Ask a question while hiding the context:\n",
    "ask(prompt,print_message=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38fa32-7581-4bfb-a692-2ce344abdadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
